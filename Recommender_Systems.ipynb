{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b7c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the correct algorithm\n",
    "from surprise import Dataset, Reader, accuracy, SVD, CoClustering, SlopeOne \n",
    "from surprise.accuracy import rmse\n",
    "from surprise.model_selection import GridSearchCV, train_test_split\n",
    "import pandas as pd\n",
    "import time\n",
    "import pathlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db15ea7c",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e87b55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kohjunkai/Documents/GitHub/CZ4032/ml-10M100K/ratings.dat\n"
     ]
    }
   ],
   "source": [
    "data_100k =  Dataset.load_builtin('ml-100k')\n",
    "data_1m = Dataset.load_builtin('ml-1m')\n",
    "path = pathlib.Path('ml-10M100K').resolve() / 'ratings.dat'\n",
    "reader = Reader(line_format=\"user item rating timestamp\",sep='::')\n",
    "print(path)\n",
    "data_10m = Dataset.load_from_file(file_path=path,reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49d5327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'user item rating timestamp', separated by '::' characters.\n",
    "# reader = Reader(line_format=\"user item rating timestamp\",sep='::')\n",
    "\n",
    "# param_grid = {\"n_epochs\": [10], \n",
    "#               \"lr_all\": [0.002,0.003,0.005], \n",
    "#               \"reg_all\": [0.01,0.02,0.03],\n",
    "#               'biased':[True,False],'random_state':[1],\n",
    "#               'verbose':[True]}\n",
    "\n",
    "# param_grid = {\"n_cltr_u\": [2,3,4], \n",
    "#               \"n_cltr_i\": [2,3,4], \n",
    "#               \"random_state\":[1],\n",
    "#               \"verbose\":[True]}\n",
    "\n",
    "# gs_SVD = GridSearchCV(SVD, param_grid, measures=[\"rmse\"], cv=3, n_jobs=-1)\n",
    "# gs_SlopeOne = GridSearchCV(SlopeOne, param_grid, measures=[\"rmse\"], cv=3, n_jobs=-1)\n",
    "# gs_CoClustering = GridSearchCV(CoClustering, param_grid, measures=[\"rmse\"], cv=3, n_jobs=-1)\n",
    "# gs_CoClustering.param_combinations\n",
    "\n",
    "# gs_SVD.fit(data_100k)\n",
    "# gs_SlopeOne.fit(data_100k)\n",
    "# gs_CoClustering.fit(data_100k)\n",
    "# print(\"SVD - 100k\")\n",
    "# print('RMSE_best_score:',gs_SVD.best_score[\"rmse\"])\n",
    "# print('RMSE_best_params',gs_SVD.best_params[\"rmse\"])\n",
    "# train_data_100k, test_data_100k = train_test_split(data_100k, test_size=0.25, random_state=1)\n",
    "# algo = gs.best_estimator[\"rmse\"]\n",
    "# algo.fit(train_data_100k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0c49af",
   "metadata": {},
   "source": [
    "## Initialise diff algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "715a28f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = SVD()\n",
    "co_clustering = CoClustering()\n",
    "slope_one = SlopeOne()\n",
    "algo_dict = {\"SVD\":svd,\"CoClustering\":co_clustering,\"SlopeOne\":slope_one}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bc733f",
   "metadata": {},
   "source": [
    "## Split training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8338da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set is 25%\n",
    "train_data_100k, test_data_100k = train_test_split(data_100k, test_size=0.25, random_state=1)\n",
    "train_data_1m, test_data_1m = train_test_split(data_1m, test_size=0.25, random_state=1)\n",
    "# train_data_10m, test_data_10m = train_test_split(data_10m, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5c366a",
   "metadata": {},
   "source": [
    "## Compare fit timing and prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a811511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 100k ---------------\n",
      "RMSE: 0.9439\n",
      "SVD: 0.9438516881940346, fit_time: 0.53\n",
      "\n",
      "RMSE: 0.9738\n",
      "CoClustering: 0.9737509607466123, fit_time: 0.84\n",
      "\n",
      "RMSE: 0.9477\n",
      "SlopeOne: 0.9477498649038465, fit_time: 0.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "\n",
    "print(\"----------- 100k ---------------\")\n",
    "for name,algo in algo_dict.items():\n",
    "    begin = time.time()\n",
    "    algo.fit(train_data_100k)\n",
    "    end = time.time()\n",
    "    predictions[name] = algo.test(test_data_100k)\n",
    "    result = accuracy.rmse(predictions[name])\n",
    "    print(f'{name}: {result}, fit_time: {round(end-begin,2)}')\n",
    "    print()\n",
    "\n",
    "# print(\"----------- 1m ---------------\")\n",
    "# for name,algo in algo_dict.items():\n",
    "#     begin = time.time()\n",
    "#     algo.fit(train_data_1m)\n",
    "#     end = time.time()\n",
    "#     predictions[name] = algo.test(test_data_1m)\n",
    "#     result = accuracy.rmse(predictions[name])\n",
    "#     print(f'{name}: {result}, fit_time: {round(end-begin,2)}')\n",
    "#     print()\n",
    "\n",
    "# print(\"----------- 10m ---------------\")\n",
    "# for name,algo in algo_dict.items():\n",
    "#     begin = time.time()\n",
    "#     algo.fit(train_data_10m)\n",
    "#     end = time.time()\n",
    "#     predictions[name] = algo.test(test_data_10m)\n",
    "#     result = accuracy.rmse(predictions[name])\n",
    "#     print(f'{name}: {result}, fit_time: {round(end-begin,2)}')\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d419e0",
   "metadata": {},
   "source": [
    "## Preparing dataframe for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a30dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_100k = pd.DataFrame(test_data_100k)\n",
    "test_data_100k = test_data_100k.rename(columns={\n",
    "    0: \"uid\",\n",
    "    1: \"iid\",\n",
    "    2: \"rating\"\n",
    "})\n",
    "\n",
    "# test_data_1m = pd.DataFrame(test_data_1m)\n",
    "# test_data_1m = test_data_1m.rename(columns={\n",
    "#     0: \"uid\",\n",
    "#     1: \"iid\",\n",
    "#     2: \"rating\"\n",
    "# })\n",
    "\n",
    "# test_data_10m = pd.DataFrame(test_data_10m)\n",
    "# test_data_10m = test_data_10m.rename(columns={\n",
    "#     0: \"uid\",\n",
    "#     1: \"iid\",\n",
    "#     2: \"rating\"\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737e8989",
   "metadata": {},
   "source": [
    "## Compare time taken to predict missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcf6c2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 100k ---------------\n",
      "SVD\n",
      "time taken to generate test predictions = 5.12 seconds\n",
      "\n",
      "CoClustering\n",
      "time taken to generate test predictions = 4.86 seconds\n",
      "\n",
      "SlopeOne\n",
      "time taken to generate test predictions = 6.99 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_dict_100k={}\n",
    "pred_dict_1m={}\n",
    "pred_dict_10m={}\n",
    "\n",
    "\n",
    "print(\"----------- 100k ---------------\")\n",
    "for name,algo in algo_dict.items():\n",
    "    pred_dict_100k[name] = []\n",
    "    begin = time.time()\n",
    "    for i in range(len(test_data_100k)):\n",
    "        y_pred = algo.predict(test_data_100k.loc[i]['uid'], test_data_100k.loc[i]['iid'])\n",
    "        y_pred = np.array(y_pred)\n",
    "        y_pred[2] = test_data_100k.loc[i]['rating']\n",
    "        pred_dict_100k[name].append(y_pred)\n",
    "    end = time.time() \n",
    "    print(name)\n",
    "    print(f\"time taken to generate test predictions = {round(end-begin, 2)} seconds\")\n",
    "    print()\n",
    "    \n",
    "# print(\"----------- 1m ---------------\")\n",
    "# for name,algo in algo_dict.items():\n",
    "#     pred_dict_1m[name] = []\n",
    "#     begin = time.time()\n",
    "#     for i in range(len(test_data_1m)):\n",
    "#         y_pred = algo.predict(test_data_1m.loc[i]['uid'], test_data_1m.loc[i]['iid'])\n",
    "#         y_pred = np.array(y_pred)\n",
    "#         y_pred[2] = test_data_1m.loc[i]['rating']\n",
    "#         pred_dict_1m[name].append(y_pred)\n",
    "#     end = time.time() \n",
    "#     print(name)\n",
    "#     print(f\"time taken to generate test predictions = {round(end-begin, 2)} seconds\")\n",
    "#     print()\n",
    "\n",
    "    \n",
    "# print(\"----------- 10m ---------------\")\n",
    "# for name,algo in algo_dict.items():\n",
    "#     pred_dict_10m[name] = []\n",
    "#     begin = time.time()\n",
    "#     for i in range(len(test_data_10m)):\n",
    "#         y_pred = algo.predict(test_data_10m.loc[i]['uid'], test_data_10m.loc[i]['iid'])\n",
    "#         y_pred = np.array(y_pred)\n",
    "#         y_pred[2] = test_data_10m.loc[i]['rating']\n",
    "#         pred_dict_10m[name].append(y_pred)\n",
    "#     end = time.time() \n",
    "#     print(name)\n",
    "#     print(f\"time taken to generate test predictions = {round(end-begin, 2)} seconds\")\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a54066",
   "metadata": {},
   "source": [
    "## Analysis of prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37858b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Iu(uid):\n",
    "    \"\"\" return the number of items rated by given user\n",
    "    args: \n",
    "      uid: the id of the user\n",
    "    returns: \n",
    "      the number of items rated by the user\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return len(trainset.ur[trainset.to_inner_uid(uid)])\n",
    "    except ValueError: # user was not part of the trainset\n",
    "        return 0\n",
    "    \n",
    "def get_Ui(iid):\n",
    "    \"\"\" return number of users that have rated given item\n",
    "    args:\n",
    "      iid: the raw id of the item\n",
    "    returns:\n",
    "      the number of users that have rated the item.\n",
    "    \"\"\"\n",
    "    try: \n",
    "        return len(trainset.ir[trainset.to_inner_iid(iid)])\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "df_dict_100k = {}\n",
    "for name,array in pred_dict_100k.items():\n",
    "    trainset = algo_dict[name].trainset\n",
    "    df_dict_100k[name] = pd.DataFrame(pred_dict_100k[name])\n",
    "    df_dict_100k[name] = df_dict_100k[name].rename(columns={\n",
    "        0: \"uid\",\n",
    "        1: \"iid\",\n",
    "        2: \"actual rating\",\n",
    "        3: \"predicted rating\",\n",
    "        4: \"-\"\n",
    "    })\n",
    "    df_dict_100k[name]['no._items_rated_by_user'] = df_dict_100k[name].uid.apply(get_Iu)\n",
    "    df_dict_100k[name]['no._user_that_rated_item'] = df_dict_100k[name].iid.apply(get_Ui)\n",
    "    df_dict_100k[name]['error'] = abs(df_dict_100k[name][\"actual rating\"]-df_dict_100k[name][\"predicted rating\"])\n",
    "\n",
    "# df_dict_1m = {}\n",
    "# for name,array in pred_dict_1m.items():\n",
    "#     trainset = algo_dict[name].trainset\n",
    "#     df_dict_1m[name] = pd.DataFrame(pred_dict_1m[name])\n",
    "#     df_dict_1m[name] = df_dict_1m[name].rename(columns={\n",
    "#         0: \"uid\",\n",
    "#         1: \"iid\",\n",
    "#         2: \"actual rating\",\n",
    "#         3: \"predicted rating\",\n",
    "#         4: \"-\"\n",
    "#     })\n",
    "#     df_dict_1m[name]['no._items_rated_by_user'] = df_dict_1m[name].uid.apply(get_Iu)\n",
    "#     df_dict_1m[name]['no._user_that_rated_item'] = df_dict_1m[name].iid.apply(get_Ui)\n",
    "#     df_dict_1m[name]['error'] = abs(df_dict_1m[name][\"actual rating\"]-df_dict_1m[name][\"predicted rating\"])\n",
    "\n",
    "# df_dict_10m = {}\n",
    "# for name,array in pred_dict_10m.items():\n",
    "#     trainset = algo_dict[name].trainset\n",
    "#     df_dict_10m[name] = pd.DataFrame(pred_dict_10m[name])\n",
    "#     df_dict_10m[name] = df_dict_10m[name].rename(columns={\n",
    "#         0: \"uid\",\n",
    "#         1: \"iid\",\n",
    "#         2: \"actual rating\",\n",
    "#         3: \"predicted rating\",\n",
    "#         4: \"-\"\n",
    "#     })\n",
    "#     df_dict_10m[name]['no._items_rated_by_user'] = df_dict_10m[name].uid.apply(get_Iu)\n",
    "#     df_dict_10m[name]['no._user_that_rated_item'] = df_dict_10m[name].iid.apply(get_Ui)\n",
    "#     df_dict_10m[name]['error'] = abs(df_dict_10m[name][\"actual rating\"]-df_dict_10m[name][\"predicted rating\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fad508",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predictions = df_dict_100k[\"SVD\"].sort_values(by='error')[:10]\n",
    "worst_predictions = df_dict_100k[\"SVD\"].sort_values(by='error')[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97a118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f305bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d66be9c",
   "metadata": {},
   "source": [
    "## Analysis of worst prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b5ce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_100k = pd.DataFrame(data_100k.__dict__['raw_ratings'], columns=['uid','iid','rating','timestamp'])\n",
    "\n",
    "df_100k.loc[df_100k['iid'] == '1090']['rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981038cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "df_100k.loc[df_100k['iid'] == '1090']['rating'].hist()\n",
    "plt.xlabel('rating')\n",
    "plt.ylabel('Number of ratings')\n",
    "plt.title('Number of ratings item 1090 has received')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97e43c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
