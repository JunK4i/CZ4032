{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b7c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the correct algorithm\n",
    "from surprise import Dataset, Reader, accuracy, SVD, CoClustering, SlopeOne \n",
    "from surprise.accuracy import rmse\n",
    "from surprise.model_selection import GridSearchCV, train_test_split\n",
    "import pandas as pd\n",
    "import time\n",
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "#cross_validate() is a function to help give accuracy metric for a \n",
    "#given set of params\n",
    "#GridSearchCV is meant to allow ntrying of diff combinations of params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e87b55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kohjunkai/Documents/GitHub/CZ4032/ml-10M100K/ratings.dat\n"
     ]
    }
   ],
   "source": [
    "data_100k =  Dataset.load_builtin('ml-100k')\n",
    "data_1m = Dataset.load_builtin('ml-1m')\n",
    "path = pathlib.Path('ml-10M100K').resolve() / 'ratings.dat'\n",
    "reader = Reader(line_format=\"user item rating timestamp\",sep='::')\n",
    "print(path)\n",
    "data_10m = Dataset.load_from_file(file_path=path,reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49d5327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'user item rating timestamp', separated by '::' characters.\n",
    "# reader = Reader(line_format=\"user item rating timestamp\",sep='::')\n",
    "\n",
    "# param_grid = {\"n_epochs\": [10], \n",
    "#               \"lr_all\": [0.002,0.003,0.005], \n",
    "#               \"reg_all\": [0.01,0.02,0.03],\n",
    "#               'biased':[True,False],'random_state':[1],\n",
    "#               'verbose':[True]}\n",
    "\n",
    "# param_grid = {\"n_cltr_u\": [2,3,4], \n",
    "#               \"n_cltr_i\": [2,3,4], \n",
    "#               \"random_state\":[1],\n",
    "#               \"verbose\":[True]}\n",
    "\n",
    "# gs_SVD = GridSearchCV(SVD, param_grid, measures=[\"rmse\"], cv=3, n_jobs=-1)\n",
    "# gs_SlopeOne = GridSearchCV(SlopeOne, param_grid, measures=[\"rmse\"], cv=3, n_jobs=-1)\n",
    "# gs_CoClustering = GridSearchCV(CoClustering, param_grid, measures=[\"rmse\"], cv=3, n_jobs=-1)\n",
    "# gs_CoClustering.param_combinations\n",
    "\n",
    "# gs_SVD.fit(data_100k)\n",
    "# gs_SlopeOne.fit(data_100k)\n",
    "# gs_CoClustering.fit(data_100k)\n",
    "# print(\"SVD - 100k\")\n",
    "# print('RMSE_best_score:',gs_SVD.best_score[\"rmse\"])\n",
    "# print('RMSE_best_params',gs_SVD.best_params[\"rmse\"])\n",
    "# train_data_100k, test_data_100k = train_test_split(data_100k, test_size=0.25, random_state=1)\n",
    "# algo = gs.best_estimator[\"rmse\"]\n",
    "# algo.fit(train_data_100k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "715a28f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = SVD()\n",
    "co_clustering = CoClustering()\n",
    "slope_one = SlopeOne()\n",
    "algo_dict = {\"SVD\":svd,\"CoClustering\":co_clustering,\"SlopeOne\":slope_one}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8338da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set is 25%\n",
    "train_data_100k, test_data_100k = train_test_split(data_100k, test_size=0.25, random_state=1)\n",
    "train_data_1m, test_data_1m = train_test_split(data_1m, test_size=0.25, random_state=1)\n",
    "# train_data_10m, test_data_10m = train_test_split(data_10m, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a811511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9436\n",
      "SVD: 0.9436080282685875, time: (1, 2)\n",
      "\n",
      "RMSE: 0.9739\n",
      "CoClustering: 0.9739038844830642, time: (1, 2)\n",
      "\n",
      "RMSE: 0.9477\n",
      "SlopeOne: 0.9477498649038465, time: (3, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "for name,algo in algo_dict.items():\n",
    "    begin = time.time()\n",
    "    algo.fit(train_data_100k)\n",
    "    predictions[name] = algo.test(test_data_100k)\n",
    "    end = time.time()\n",
    "    result = accuracy.rmse(predictions[name])\n",
    "    print(f'{name}: {result}, time: {round(end-begin,2)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a30dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_100k = pd.DataFrame(test_data_100k)\n",
    "test_data_100k = test_data_100k.rename(columns={\n",
    "    0: \"uid\",\n",
    "    1: \"iid\",\n",
    "    2: \"rating\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467af8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD\n",
      "time taken to generate test predictions = 5.01 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_dictionary={}\n",
    "co_clustering_pred_array = []\n",
    "slope_one_pred_array = []\n",
    "\n",
    "for name,algo in algo_dict.items():\n",
    "    begin = time.time()\n",
    "    pred_dictionary[name] = []\n",
    "    for i in range(len(test_data_100k)):\n",
    "        y_pred = algo.predict(test_data_100k.loc[i]['uid'], test_data_100k.loc[i]['iid'])\n",
    "        y_pred = np.array(y_pred)\n",
    "        y_pred[2] = test_data_100k.loc[i]['rating']\n",
    "        pred_dictionary[name].append(y_pred)\n",
    "    end = time.time() \n",
    "    print(name)\n",
    "    print(f\"time taken to generate test predictions = {round(end-begin, 2)} seconds\")\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37858b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {}\n",
    "for name,array in pred_dictionary.items():\n",
    "    df_dict[name] = pd.DataFrame(pred_dictionary[name])\n",
    "    df_dict[name] = df_dict[name].rename(columns={\n",
    "        0: \"uid\",\n",
    "        1: \"iid\",\n",
    "        2: \"actual rating\",\n",
    "        3: \"predited rating\",\n",
    "        4: \"-\"\n",
    "    })\n",
    "#     df_dict[name]['err'] = abs(df_dict[name].est-df_dict[name].r_ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fad508",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict[\"SVD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97a118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict[\"CoClustering\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f305bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict[\"SlopeOne\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b5ce67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
